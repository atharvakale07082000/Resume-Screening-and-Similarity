# -*- coding: utf-8 -*-
"""Resume_Screening.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1AoTdazFFxLak37zlGulMagn0vm0rJebB

# Importing Data from Local Storage & Saving file in the runtime storage
---
"""

from google.colab import files
import io
import pandas as pd


uploaded = files.upload()

df = pd.read_csv(io.BytesIO(uploaded['Resum.csv']))
print(df)

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import regex as re

df.shape

"""# DESCRIBE THE **DATASET**"""

df.describe()

"""#BAR PLOT OF THE DATA"""

import seaborn as sns
plt.figure(figsize=(15,15))
plt.xticks(rotation=90)
sns.countplot(y="Category", data=df)
plt.title("Category Distribution")

# Save the plot as a JPEG image
plt.savefig("category_distribution.jpg")

"""# Pie Chart"""

from matplotlib.gridspec import GridSpec

targetCounts=df["Category"].value_counts()
targetLabels=df["Category"].unique()

plt.figure(1,figsize=(25,25))
the_grid=GridSpec(2,2)

cmap = plt.get_cmap('coolwarm')
colors = [cmap(i) for i in np.linspace(0, 1, 3)]
plt.subplot(the_grid[0, 1], aspect=1, title='CATEGORY DISTRIBUTION')

source_pie=plt.pie(targetCounts,labels=targetLabels,autopct='%1.1f%%', shadow=True, colors=colors)
plt.show()
plt.savefig("category_distribution_pie.jpg")

print ("Displaying the distinct categories of resume and the number of records belonging to each category -")
print (df['Category'].value_counts())

"""# Made a Function using Regular Expression whih clwnas the resume of any obsolete characters which can be a issue while Encoding the data"""

def cleanResume(resumeText):
    resumeText = re.sub('http\S+\s*', ' ', resumeText)  # remove URLs
    resumeText = re.sub('RT|cc', ' ', resumeText)  # remove RT and cc
    resumeText = re.sub('#\S+', '', resumeText)  # remove hashtags
    resumeText = re.sub('@\S+', '  ', resumeText)  # remove mentions
    resumeText = re.sub('[%s]' % re.escape("""!"#$%&'()*+,-./:;<=>?@[\]^_`{|}~"""), ' ', resumeText)  # remove punctuations
    resumeText = re.sub(r'[^\x00-\x7f]',r' ', resumeText)
    resumeText = re.sub('\s+', ' ', resumeText)  # remove extra whitespace
    return resumeText
df['cleaned_resume'] = df.Resume.apply(lambda x: cleanResume(str(x)))
print (df['cleaned_resume'])

df.dropna()
df.describe()

df.head(5)

import nltk
nltk.download('stopwords')
nltk.download('punkt')
from nltk.corpus import stopwords
import string
from wordcloud import WordCloud

oneSetOfStopWords = set(stopwords.words('english')+['``',"''"])
totalWords =[]
Sentences = df['cleaned_resume'].values
cleanedSentences = ""
for i in range(0,962):
    cleanedText = cleanResume(Sentences[i])
    cleanedSentences += cleanedText
    requiredWords = nltk.word_tokenize(cleanedText)
    for word in requiredWords:
        if word not in oneSetOfStopWords and word not in string.punctuation:
            totalWords.append(word)

wordfreqdist = nltk.FreqDist(totalWords)
mostcommon = wordfreqdist.most_common(500)
print(mostcommon)

wc = WordCloud().generate(cleanedSentences)
plt.figure(figsize=(15,15))
plt.imshow(wc, interpolation='bilinear')
plt.axis("off")
plt.show()

"""# LABEL ENCODING - TO convert categorical Data to Numerical Data"""

from sklearn.preprocessing import LabelEncoder
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.neighbors  import KNeighborsClassifier
from sklearn.metrics import classification_report

v = ['Category']
le = LabelEncoder()
for i in v:
    df[i] = le.fit_transform(df[i])
df[i]

from sklearn.preprocessing import LabelEncoder

var_mod = ['Category']
le = LabelEncoder()
for i in var_mod:
    df[i] = le.fit_transform(df[i])
print ("CONVERTED THE CATEGORICAL VARIABLES INTO NUMERICALS")

df['Category']

"""# USE TF ID VECTORIZER TO CONVERT CATEGORICAL VARIABLES INTO VECTORS

1.   List item
2.   List item



"""

required_Text = df['cleaned_resume'].values
required_Target = df['Category'].values
w = TfidfVectorizer(
    sublinear_tf=True,
    stop_words='english',
    max_features=1000)

w.fit(required_Text)

word_features = w.transform(required_Text)

word_features

"""# MODEL TRAINING"""

from sklearn.metrics import classification_report
from sklearn.preprocessing import LabelEncoder
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.neighbors  import KNeighborsClassifier
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier



X_train,X_test,y_train,y_test = train_test_split(word_features,required_Target,random_state=0, test_size=0.3)
print(X_train.shape)

classifier = RandomForestClassifier()
classifier.fit(X_train, y_train)

from sklearn.multiclass import OneVsRestClassifier

from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.ensemble import RandomForestClassifier

models = {
    'K-Nearest Neighbors' : KNeighborsClassifier(),
    'Logistic Regression' : LogisticRegression(),
    'Support Vector Machine' : SVC(),
    'Random Forest' : RandomForestClassifier()
}

model_list=[]
for model in models.values():
    model_list.append(OneVsRestClassifier(model))

print(model_list)

for i in model_list:
    i.fit(X_train, y_train)
    print(f'{i} trained')

print("*"*60)
print("all models trained")

for count, value in enumerate(model_list):
    print(f"Accuracy of {value} on training set :", model_list[count].score(X_train, y_train))
    print(f"Accuracy of {value} on test set :", model_list[count].score(X_test, y_test))
    print("*"*100)

print("all scores calculated")

"""#Printing the results"""

prediction = classifier.predict(X_test)
print(prediction)

"""#Checking the Accuracy of mode on Training an Testing Set"""

print('Accuracy of RFC on training set: {:.2f}'.format(classifier.score(X_train, y_train)))
print('Accuracy of RFC Classifier on test set: {:.2f}'.format(classifier.score(X_test, y_test)))

"""#Printing the Classification Report"""

print(classification_report(y_test, prediction))
y_pred = classifier.predict(X_test)
print(f'---------------------------------\n| Training Accuracy   :- {(classifier.score(X_train, y_train)*100).round(2)}% |')
print(f'---------------------------------\n| Testing Accuracy :- {(classifier.score(X_test, y_test)*100).round(2)}% |\n---------------------------------')

import nltk
from nltk import word_tokenize
from nltk.stem import WordNetLemmatizer, PorterStemmer
from nltk.corpus import wordnet
from sklearn.ensemble import RandomForestClassifier

from sklearn.feature_extraction.text import CountVectorizer


inputs = df['cleaned_resume']
inputs
labels = df['Category']
inputs_train, inputs_test, Ytrain, Ytest = train_test_split(inputs, labels, random_state=42)

vectorizer = CountVectorizer()
Xtrain = w.fit_transform(inputs_train)
Xtest = w.transform(inputs_test)
Xtrain

Xtest



vectorizer4 = CountVectorizer(stop_words='english')
Xtrain4 = w.fit_transform(inputs_train)
Xtest4 = w.transform(inputs_test)
final_model = RandomForestClassifier(max_depth = 100)
final_model.fit(Xtrain4, Ytrain)
print("train score:", final_model.score(Xtrain4, Ytrain))
print("test score:",final_model.score(Xtest4, Ytest))

def new_inputs(resumes):
    cleaned_resumes = resumes.apply(lambda x:cleanResume(x))
    transformed_resumes = w.transform(cleaned_resumes)
    return transformed_resumes

x = "Languages: Python, C , SQL, Prolog Development: React.js, CSS, HTML Databases: MySQL, MongoDB Data Science: Tableau,PCA, Pandas, NumPy, Matplotlib,Inferential Statistics, Linear algebra Machine Learning: Scikit-Learn"
new_df = pd.Series(x)
new_df

pred = classifier.predict(new_inputs(new_df))
pred